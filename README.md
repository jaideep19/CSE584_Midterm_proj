# CSE584_Midterm_proj

# LLM Output Classification Project

This project aims to classify which large language model (LLM) generated given output texts. Two distinct models were used:

1. **Stella Embeddings with a Neural Network Classifier**
2. **Fine-tuned BERT Model with its Tokenizer**

## Project Overview

The main goal of this project was to create models capable of distinguishing the outputs generated by different LLMs. The dataset used contained LLM outputs paired with the corresponding prompts. To solve this problem, two approaches were adopted: a custom embedding-based neural network classifier using Stella embeddings, and a transformer-based classifier leveraging a fine-tuned BERT model.

### 1. Stella Embeddings + Neural Network Classifier

- **Embedding Generation**: Used the pre-trained `dunzhang/stella_en_1.5B_v5` model from Hugging Face to generate embeddings for input prompts and LLM-generated outputs. Each text (prompt and output) was separately encoded, and the resulting embeddings were combined.
- **Neural Network Classifier**: The combined embeddings were then passed into a simple feedforward neural network to predict which LLM was used to generate the output.
- **Training**: The neural network was trained on these embeddings, with training accuracy and loss monitored to ensure convergence.

### 2. Fine-tuned BERT Model

- **Model Selection**: `bert-base-uncased` from the Hugging Face library was chosen for fine-tuning. This pre-trained model was selected due to its general-purpose nature and well-documented training stability.
- **Tokenizer**: The BERT tokenizer was used to prepare the input data for the model. Specifically, both the input prompt and LLM-generated output were tokenized separately.
- **Fine-tuning**: BERT was fine-tuned on the dataset to classify the LLM that generated each given output. Only selected layers of BERT were fine-tuned to reduce computational cost and prevent overfitting.

## Dataset

The dataset used for training and evaluation consists of the following columns:

- `Input Prompt`: The initial text prompt used for LLM generation.
- `LLM Output`: The corresponding generated output from an LLM.
- `Used LLM`: The LLM that generated the output (used as the label).

Data preprocessing involved encoding both the input prompt and LLM output separately, then combining the embeddings for classification.

## Training Details

- **Stella+NN Classifier**: The neural network model was trained using the combined embeddings from `dunzhang/stella_en_1.5B_v5`. The training loop included monitoring accuracy and loss per epoch.
- **Fine-tuned BERT**: The BERT model was fine-tuned for text classification with a focus on adjusting only a subset of its layers. The model training included monitoring both training loss and accuracy for each epoch.

## Results

- **Stella+NN Classifier**: Achieved an accuracy of **85%** on the test set.
- **Fine-tuned BERT**: Achieved an accuracy of **89.92%** on the test set.
- **Label Analysis**: Further analysis was conducted on the predictions to determine which labels were most frequently predicted by each model. Graphs were also created to visualize model performance and prediction distribution.

## Graphical Analysis

Graphs were generated to provide a visual understanding of:

- **Loss and Accuracy per Epoch**: Showing the training process for each model.
- **Label Distribution**: Highlighting the most frequent predictions for each model to identify any biases.

## Usage

To use either of the models, you can follow the steps in the provided code to:

1. Load the pre-trained Stella or BERT model.
2. Preprocess your dataset by encoding the input prompts and outputs.
3. Train the classifier or directly use the pre-trained/fine-tuned models for inference.

### Requirements

- Python 3.7+
- PyTorch
- Transformers
- SentenceTransformers
- scikit-learn
- pandas

### Running the Code

- Clone the repository and install the dependencies.
- Prepare your dataset in a CSV file with columns: `Input Prompt`, `LLM Output`, and `Used LLM`.
- Run the training script to train the models or use the evaluation script to check model performance.

## Future Work

- **Model Improvements**: Experiment with more advanced architectures or ensemble methods to improve accuracy.
- **Generalizability**: Train the model on outputs from more diverse LLMs to improve generalizability.

## License

This project is open-source under the MIT License.


